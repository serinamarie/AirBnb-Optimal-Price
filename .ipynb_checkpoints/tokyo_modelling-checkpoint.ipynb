{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipynb in /home/guillermo/anaconda3/lib/python3.7/site-packages (0.5.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas_profiling'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-eb4b15bccd42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mipynb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokyo_NLP\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/repos/Data-science/tokyo_NLP.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m    \u001b[0;34m\"cell_type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"code\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m    \u001b[0;34m\"execution_count\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m    \u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m    \"outputs\": [\n\u001b[1;32m      8\u001b[0m     {\n",
      "\u001b[0;32m~/Documents/repos/Data-science/Tokyo_deploy.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m    \u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m    \"outputs\": [\n\u001b[0;32m----> 8\u001b[0;31m     {\n\u001b[0m\u001b[1;32m      9\u001b[0m      \u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"stderr\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m      \u001b[0;34m\"output_type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas_profiling'"
     ]
    }
   ],
   "source": [
    "from ipynb.fs.full.tokyo_NLP import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(listings_clean_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = df.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_col = ['accommodates','bathrooms',\n",
    "                 'cleaning_fee',\n",
    "                'minimum_nights','price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numerical_col].hist(figsize=(10,11));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transforming columns because some features are highly skewed. \n",
    "numerical_col = [i for i in numerical_col if i not in ['accommodates']] # Removing items not to be transformed\n",
    "\n",
    "for col in numerical_col:\n",
    "        df[col] = df[col].astype('float64').replace(0.0, 0.01) # Replacing 0s with 0.01\n",
    "        df[col] = np.log(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target\n",
    "y_price = df['price']\n",
    "X_price = df.drop('price', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_price = pd.DataFrame(scaler.fit_transform(X_price), columns=list(X_price.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_price, X_test_price, y_train_price, y_test_price = train_test_split(\n",
    "                                                           X_price, y_price, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error,r2_score,explained_variance_score\n",
    "\n",
    "xgb_reg = xgb.XGBRegressor()\n",
    "xgb_reg.fit(X_train_price, y_train_price)\n",
    "training_preds_xgb_reg = xgb_reg.predict(X_train_price)\n",
    "val_preds_xgb_reg = xgb_reg.predict(X_test_price)\n",
    "\n",
    "print(\"\\nTraining MSE:\", round(mean_squared_error(y_train_price, training_preds_xgb_reg),3))\n",
    "print(\"Validation MSE:\", round(mean_squared_error(y_test_price, val_preds_xgb_reg),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTraining r2:\", round(r2_score(y_train_price, training_preds_xgb_reg),3))\n",
    "print(\"Validation r2:\", round(r2_score(y_test_price, val_preds_xgb_reg),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_weights_xgb_reg = pd.DataFrame(xgb_reg.feature_importances_, columns=['weight'], index=X_train_price.columns)\n",
    "ft_weights_xgb_reg.sort_values('weight', inplace=True)\n",
    "#ft_weights_xgb_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop feature weights of 0 \n",
    "ft_weights_xgb_reg = ft_weights_xgb_reg[(ft_weights_xgb_reg != 0).all(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting feature importances\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,32))\n",
    "plt.barh(ft_weights_xgb_reg.index, ft_weights_xgb_reg.weight, align='center') \n",
    "plt.title(\"Feature importances in the XGBoost model\", fontsize=14)\n",
    "plt.xlabel(\"Feature importance\")\n",
    "plt.margins(y=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets use availability_30 as Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Target\n",
    "# y_30 = df['availability_30']\n",
    "# X_30 = df.drop(['availability_30','availability_90'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_30 = pd.DataFrame(scaler.fit_transform(X_30), columns=list(X_30.columns))\n",
    "# X_train_30, X_test_30, y_train_30, y_test_30 = train_test_split(X_30, y_30, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_reg = xgb.XGBRegressor()\n",
    "# xgb_reg.fit(X_train_30, y_train_30)\n",
    "# training_preds_xgb_reg = xgb_reg.predict(X_train_30)\n",
    "# val_preds_xgb_reg = xgb_reg.predict(X_test_30)\n",
    "\n",
    "# print(\"\\nTraining MSE:\", round(mean_squared_error(y_train_30, training_preds_xgb_reg),3))\n",
    "# print(\"Validation MSE:\", round(mean_squared_error(y_test_30, val_preds_xgb_reg),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft_weights_xgb_reg = pd.DataFrame(xgb_reg.feature_importances_, columns=['weight'], index=X_train_30.columns)\n",
    "# ft_weights_xgb_reg.sort_values('weight', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop feature weights of 0 \n",
    "# ft_weights_xgb_reg = ft_weights_xgb_reg[(ft_weights_xgb_reg != 0).all(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotting feature importances\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(8,30))\n",
    "# plt.barh(ft_weights_xgb_reg.index, ft_weights_xgb_reg.weight, align='center') \n",
    "# plt.title(\"Feature importances in the XGBoost model\", fontsize=14)\n",
    "# plt.xlabel(\"Feature importance\")\n",
    "# plt.margins(y=0.01)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Availability_30 has a bigger MSE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets use availability_90 as the Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Target\n",
    "# y_90 = df['availability_90']\n",
    "# X_90 = df.drop(['availability_30','availability_90'],axis=1)\n",
    "\n",
    "# X_90 = pd.DataFrame(scaler.fit_transform(X_90), columns=list(X_90.columns))\n",
    "# X_train_90, X_test_90, y_train_90, y_test_90 = train_test_split(X_90, y_90, test_size=0.2, random_state=42)\n",
    "\n",
    "# xgb_reg = xgb.XGBRegressor()\n",
    "# xgb_reg.fit(X_train_90, y_train_90)\n",
    "# training_preds_xgb_reg = xgb_reg.predict(X_train_90)\n",
    "# val_preds_xgb_reg = xgb_reg.predict(X_test_90)\n",
    "\n",
    "# print(\"\\nTraining MSE:\", round(mean_squared_error(y_train_90, training_preds_xgb_reg),3))\n",
    "# print(\"Validation MSE:\", round(mean_squared_error(y_test_90, val_preds_xgb_reg),3))\n",
    "\n",
    "# ft_weights_xgb_reg = pd.DataFrame(xgb_reg.feature_importances_, columns=['weight'], index=X_train_90.columns)\n",
    "# ft_weights_xgb_reg.sort_values('weight', inplace=True)\n",
    "# # Drop feature weights of 0 \n",
    "# ft_weights_xgb_reg = ft_weights_xgb_reg[(ft_weights_xgb_reg != 0).all(1)]\n",
    "\n",
    "# # Plotting feature importances\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(8,30))\n",
    "# plt.barh(ft_weights_xgb_reg.index, ft_weights_xgb_reg.weight, align='center') \n",
    "# plt.title(\"Feature importances in the XGBoost model\", fontsize=14)\n",
    "# plt.xlabel(\"Feature importance\")\n",
    "# plt.margins(y=0.01)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Availability_90 has a huge MSE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers, optimizers, regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model without regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_price, X_test_price, y_train_price, y_test_price = train_test_split(\n",
    "                                                           X_price, y_price, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "nn = models.Sequential()\n",
    "nn.add(layers.Dense(128, input_shape=(X_train_price.shape[1],), activation='relu'))\n",
    "nn.add(layers.Dense(256, activation='relu'))\n",
    "nn.add(layers.Dense(256, activation='relu'))\n",
    "nn.add(layers.Dense(512, activation='relu'))\n",
    "nn.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "# Compiling the model\n",
    "nn.compile(loss='mean_squared_error',\n",
    "            optimizer='adam',\n",
    "            metrics=['mean_squared_error'])\n",
    "\n",
    "# Model summary\n",
    "print(nn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "nn_history = nn.fit(X_train_price,\n",
    "                  y_train_price,\n",
    "                  epochs=150,\n",
    "                  batch_size=256,\n",
    "                  validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model_evaluation(model,X_train, X_test, y_train, y_test, skip_epochs=0,):\n",
    "    \"\"\"\n",
    "    For a given neural network model that has already been fit, prints for the train and tests sets the MSE and r squared\n",
    "    values, a line graph of the loss in each epoch, and a scatterplot of predicted vs. actual values with a line\n",
    "    representing where predicted = actual values. Optionally, a value for skip_epoch can be provided, which skips that\n",
    "    number of epochs in the line graph of losses (useful in cases where the loss in the first epoch is orders of magnitude\n",
    "    larger than subsequent epochs). Training and test sets can also optionally be specified.\n",
    "    \"\"\"\n",
    "\n",
    "    # MSE and r squared values\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    print(\"Training MSE:\", round(mean_squared_error(y_train, y_train_pred),4))\n",
    "    print(\"Validation MSE:\", round(mean_squared_error(y_test, y_test_pred),4))\n",
    "    print(\"\\nTraining r2:\", round(r2_score(y_train, y_train_pred),4))\n",
    "    print(\"Validation r2:\", round(r2_score(y_test, y_test_pred),4))\n",
    "    \n",
    "    # Line graph of losses\n",
    "    model_results = model.history.history\n",
    "    plt.plot(list(range((skip_epochs+1),len(model_results['loss'])+1)), model_results['loss'][skip_epochs:], label='Train')\n",
    "    plt.plot(list(range((skip_epochs+1),len(model_results['val_loss'])+1)), model_results['val_loss'][skip_epochs:], label='Test', color='green')\n",
    "    plt.legend()\n",
    "    plt.title('Training and test loss at each epoch', fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_evaluation(nn,X_train_price,X_test_price, y_train_price, y_test_price, skip_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model with regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "nn2 = models.Sequential()\n",
    "nn2.add(layers.Dense(128, input_shape=(X_train_price.shape[1],), kernel_regularizer=regularizers.l1(0.005), activation='relu'))\n",
    "nn2.add(layers.Dense(256, kernel_regularizer=regularizers.l1(0.005), activation='relu'))\n",
    "nn2.add(layers.Dense(256, kernel_regularizer=regularizers.l1(0.005), activation='relu'))\n",
    "nn2.add(layers.Dense(512, kernel_regularizer=regularizers.l1(0.005), activation='relu'))\n",
    "nn2.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "# Compiling the model\n",
    "nn2.compile(loss='mean_squared_error',\n",
    "            optimizer='adam',\n",
    "            metrics=['mean_squared_error'])\n",
    "\n",
    "# Model summary\n",
    "print(nn2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "nn2_history = nn2.fit(X_train_price,\n",
    "                  y_train_price,\n",
    "                  epochs=150,\n",
    "                  batch_size=256,\n",
    "                  validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_evaluation(nn2,X_train_price,X_test_price, y_train_price, y_test_price, skip_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net with Kernal Regularizers is best performing with lowest MSE and higest R2 score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "# Pickle the darn thing! ðŸ¥’\n",
    "model_name = '/Users/karthikmahendra/Desktop/AirBnB/ABB.pkl' # path to where you want the file\n",
    "pickle.dump(xgb_reg, open(model_name, 'wb')) # kitty = the name of your model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tst = X_train_price.iloc[0]\n",
    "y_tst = y_train_price.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(model_name, 'rb'))\n",
    "result = loaded_model.score(X_tst, y_tst)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
